#数据集：是供模型训练，优化参数的样本
#模型：为了解决某一类特定问题，实现从输入到输出映射的算法
#优化器：根据损失函数对模型的参数做出最小化的改动以减小损失函数，进而求解输入对输出的更好的拟合
#损失函数：描述模型产生的预测值与真实值之间偏差的函数（单个样本的误差，有别于代价函数）
#梯度下降：为了寻找代价函数的最低点，通过减去梯度和学习率的乘积迭代参数。代码中采用随机梯度算法SGD,计算速度快，但不保证下降最快
#梯度下降步骤：定义代价函数——>选择起始点——>计算梯度——>按照学习率前进——>迭代第三，四步
#激活函数：加入非线性因素
#卷积层：提取图像特征，便于后续图像计算，相比全连接层还能减少训练参数的个数。所以卷积核也叫过滤器。为保证输入输出维度一致，可以在矩阵外围补零
#池化层：把局部多个神经元的输出组合成下层单个神经元减少维度，放大主要特征，也能避免过拟合
#反向传播：神经网络中加速计算参数梯度值的方法，核心是链式法则
